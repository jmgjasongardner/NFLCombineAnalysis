---
title: "Bayesian_PickNumber"
output: pdf_document
---

Packages
```{r echo = TRUE}
library(LearnBayes)
```

Initial Data Set for Predicting
```{r echo = TRUE}
prosp <- read.csv('Prospects2020.csv')
```

Running Back Bayesian Inference
```{r echo = TRUE}
# Data Formatting 
rb <- read.csv("RBs.csv")
rb.full <- rb[is.na(rb$Pick.Number) == FALSE, ]
rb.full <- rb.full[is.na(rb.full$Weight) == FALSE, ]
rb.full <- rb.full[is.na(rb.full$Forty) == FALSE, ]
rb.full <- rb.full[is.na(rb.full$ThreeCone) == FALSE, ]
rb.full <- rb.full[is.na(rb.full$Broad) == FALSE, ]

prosp_rb <- subset(prosp, Position == "RB")
prosp_rb_full <- prosp_rb[is.na(prosp_rb$Weight) == FALSE, ]
prosp_rb_full <- prosp_rb_full[is.na(prosp_rb_full$Forty) == FALSE, ]
prosp_rb_full <- prosp_rb_full[is.na(prosp_rb_full$ThreeCone) == FALSE, ]
prosp_rb_full <- prosp_rb_full[is.na(prosp_rb_full$Broad) == FALSE, ]
future <- as.data.frame(cbind(prosp_rb_full$Weight, prosp_rb_full$Forty, prosp_rb_full$ThreeCone,
                              prosp_rb_full$Broad))
names(future) <- c("Weight", "Forty", "ThreeCone","Broad")

# Initial Regression
rblm3 <- lm(Pick.Number ~ Weight + Forty + ThreeCone + Broad, data = rb.full)
summary(rblm3)
rb_bay <- as.data.frame(cbind(rb.full$Pick.Number, rb.full$Weight, rb.full$Forty, rb.full$ThreeCone,
                              rb.full$Broad))
names(rb_bay) <- c("Pick.Number", "Weight", "Forty", "ThreeCone", "Broad")

# Bayesian Inference
fit = lm(Pick.Number ~ Weight + Forty + ThreeCone + Broad, data = rb_bay)
summary(fit)

y = rb_bay$Pick.Number
n = length(y)
x = as.matrix(cbind(rep(1,n), rb_bay[,2:5]))

  ## Compute quantities for speed
Vb = solve(t(x) %*% x) 
betahat = Vb %*% t(x) %*% y
s2 = t(y - x %*% betahat) %*% (y - x %*% betahat)

  ## MCMC settings
T = 10000
k = ncol(x)
sigma2 = rep(NA, T)
beta = matrix(NA, T, k)

  ## Sample from joint posterior
for (t in 1:T){
  
  ## Draw sigma2
  sigma2[t] = rigamma(1, (n-k)/2, s2/2)
  
  ## Draw beta
  beta[t,] = rmnorm(1, betahat, sigma2[t] * Vb)
  
}
par(mfrow=c(2,2))
hist(beta[,2], main = "Weight", xlab = expression(beta[1]))
hist(beta[,3], main = "40 Yd Dash", xlab = expression(beta[2]))
hist(beta[,4], main = "Three Cone Drill", xlab = expression(beta[3]))
hist(beta[,5], main = "Broad Jump", xlab = expression(beta[4]))
hist(sigma2, main = "Variance", xlab = expression(sigma^2))
par(mfrow=c(1,1))

cat("Posterior mean of beta:", apply(beta, 2, mean))
cat("Quantiles for beta:") 
    apply(beta, 2, quantile, c(0.025, 0.5, 0.975))
cat("Quantiles for sigma^2:", quantile(sigma2, c(0.025, 0.5, 0.975)))

x_f00 = data.frame(Weight = future[,1],
                 Forty = future[,2],
                 ThreeCone = future[,3], 
                 Broad = future[,4])

# Predicting
predict(fit, x_f00, interval = "prediction")

# Predicting with Bayes
x_f = as.matrix(cbind(rep(1,11),x_f00))
n_f = nrow(x_f)

ytilde = matrix(NA, T, n_f)
for (t in 1:T){
  ytilde[t,] = rmnorm(1, x_f %*% beta[t,], sigma2[t]*diag(n_f))
}

## Distribution of posterior predictive samples
c.labels = c("A", "B", "C", "D")
par(mfrow=c(2,2))
for (j in 1:4){
  hist(ytilde[ , j], main = paste("Covariate Set", c.labels[j]),
       xlab = "log time", prob = T, breaks = 20)
}
par(mfrow=c(1,1))

## Posterior mean / 95% credible interval 
cbind(apply(ytilde, 2, mean),
      t(apply(ytilde, 2, quantile, c(0.025, 0.975))))
```

Quarterback Bayesian Inference 
```{r echo = TRUE}
# Data Formatting 
qb <- read.csv("QBs.csv")
qb.full <- qb[is.na(qb$Broad) == FALSE, ]

prosp_qb <- subset(prosp, Position == "QB")
prosp_qb_full <- prosp_qb[is.na(prosp_qb$Broad) == FALSE, ]
future <- as.data.frame(cbind(prosp_qb_full$Broad))
names(future) <- c("Broad")

# Initial Regression
qblm3 <- lm(Pick.Number ~ Broad, data = qb.full)
summary(qblm3)
qb_bay <- as.data.frame(cbind(qb.full$Pick.Number, qb.full$Broad))
names(qb_bay) <- c("Pick.Number", "Broad")

# Bayesian Inference
fit = lm(Pick.Number ~ Broad, data = qb_bay)
summary(fit)

y = qb_bay$Pick.Number
n = length(y)
x = as.matrix(cbind(rep(1,n), qb_bay[,2]))

  ## Compute quantities for speed
Vb = solve(t(x) %*% x) 
betahat = Vb %*% t(x) %*% y
s2 = t(y - x %*% betahat) %*% (y - x %*% betahat)

  ## MCMC settings
T = 10000
k = ncol(x)
sigma2 = rep(NA, T)
beta = matrix(NA, T, k)

  ## Sample from joint posterior
for (t in 1:T){
  
  ## Draw sigma2
  sigma2[t] = rigamma(1, (n-k)/2, s2/2)
  
  ## Draw beta
  beta[t,] = rmnorm(1, betahat, sigma2[t] * Vb)
  
}
par(mfrow=c(2,2))
hist(beta[,2], main = "Broad Jump", xlab = expression(beta[1]))
hist(sigma2, main = "Variance", xlab = expression(sigma^2))
par(mfrow=c(1,1))

cat("Posterior mean of beta:", apply(beta, 2, mean))
cat("Quantiles for beta:") 
    apply(beta, 2, quantile, c(0.025, 0.5, 0.975))
cat("Quantiles for sigma^2:", quantile(sigma2, c(0.025, 0.5, 0.975)))

x_f00 = data.frame(Broad = future[,1])

# Predicting
predict(fit, x_f00, interval = "prediction")

# Predicting with Bayes
x_f = as.matrix(cbind(rep(1,13),x_f00))
n_f = nrow(x_f)

ytilde = matrix(NA, T, n_f)
for (t in 1:T){
  ytilde[t,] = rmnorm(1, x_f %*% beta[t,], sigma2[t]*diag(n_f))
}

## Distribution of posterior predictive samples
c.labels = c("A", "B", "C", "D")
par(mfrow=c(2,2))
for (j in 1:4){
  hist(ytilde[ , j], main = paste("Covariate Set", c.labels[j]),
       xlab = "log time", prob = T, breaks = 20)
}
par(mfrow=c(1,1))

## Posterior mean / 95% credible interval 
cbind(apply(ytilde, 2, mean),
      t(apply(ytilde, 2, quantile, c(0.025, 0.975))))
```

Linebackers Bayesian Inference
```{r echo = TRUE}
# Data Formatting 
lb <- read.csv("LBs.csv")
lb.full <- lb[is.na(lb$Weight) == FALSE, ]
lb.full <- lb.full[is.na(lb.full$Broad) == FALSE, ]
lb.full <- lb.full[is.na(lb.full$Forty) == FALSE, ]
lb.full <- lb.full[is.na(lb.full$Shuttle) == FALSE, ]

prosp_lb <- subset(prosp, Position == "LB")
prosp_lb_full <- prosp_lb[is.na(prosp_lb$Weight) == FALSE, ]
prosp_lb_full <- prosp_lb_full[is.na(prosp_lb_full$Broad) == FALSE, ]
prosp_lb_full <- prosp_lb_full[is.na(prosp_lb_full$Forty) == FALSE, ]
prosp_lb_full <- prosp_lb_full[is.na(prosp_lb_full$Shuttle) == FALSE, ]
future <- as.data.frame(cbind(prosp_lb_full$Weight, prosp_lb_full$Broad, prosp_lb_full$Forty,
                              prosp_lb_full$Shuttle))
names(future) <- c("Weight", "Broad", "Forty", "Shuttle")
```

Defensive Backs Bayesian Inference
```{r echo = TRUE}
# Data Formatting
db <- read.csv("DBs.csv")
db.full <- db[is.na(db$Forty) == FALSE, ]
db.full <- db.full[is.na(db.full$Broad) == FALSE, ]
db.full <- db.full[is.na(db.full$ThreeCone) == FALSE, ]

prosp_db <- subset(prosp, Position == "DB")
prosp_db_full <- prosp_db[is.na(prosp_db$Forty) == FALSE, ]
prosp_db_full <- prosp_db_full[is.na(prosp_db_full$Broad) == FALSE, ]
prosp_db_full <- prosp_db_full[is.na(prosp_db_full$ThreeCone) == FALSE, ]
future <- as.data.frame(cbind(prosp_db_full$Forty, prosp_db_full$Broad, prosp_db_full$ThreeCone))
names(future) <- c("Forty", "Broad", "ThreeCone")

# Initial Regression 
dblm2 <- lm(Pick.Number ~  Forty +  Broad + ThreeCone, data = db.full)
summary(dblm2)
db_bay <- as.data.frame(cbind(db.full$Pick.Number, db.full$Forty, db.full$Broad, db.full$ThreeCone))
names(db_bay) <- c("Pick.Number", "Forty", "Broad", "ThreeCone")

# Bayesian Inference 
fit = lm(Pick.Number ~ Forty + Broad + ThreeCone, data = db_bay)
summary(fit)

y = db_bay$Pick.Number
n = length(y)
x = as.matrix(cbind(rep(1,n), db_bay[,2:4]))

  ## Compute quantities for speed
Vb = solve(t(x) %*% x) 
betahat = Vb %*% t(x) %*% y
s2 = t(y - x %*% betahat) %*% (y - x %*% betahat)

  ## MCMC settings
T = 10000
k = ncol(x)
sigma2 = rep(NA, T)
beta = matrix(NA, T, k)

  ## Sample from joint posterior
for (t in 1:T){
  
  ## Draw sigma2
  sigma2[t] = rigamma(1, (n-k)/2, s2/2)
  
  ## Draw beta
  beta[t,] = rmnorm(1, betahat, sigma2[t] * Vb)
  
}
par(mfrow=c(2,2))
hist(beta[,2], main = "Forty", xlab = expression(beta[1]))
hist(beta[,3], main = "Broad", xlab = expression(beta[2]))
hist(beta[,4], main = "ThreeCone", xlab = expression(beta[3]))
hist(sigma2, main = "Variance", xlab = expression(sigma^2))
par(mfrow=c(1,1))

cat("Posterior mean of beta:", apply(beta, 2, mean))
cat("Quantiles for beta:") 
    apply(beta, 2, quantile, c(0.025, 0.5, 0.975))
cat("Quantiles for sigma^2:", quantile(sigma2, c(0.025, 0.5, 0.975)))

x_f00 = data.frame(Forty = future[,1],
                 Broad = future[,2],
                 ThreeCone = future[,3])

# Predictring
predict(fit, x_f00, interval = "prediction")

# Predicting with Bayes
x_f = as.matrix(cbind(rep(1,14),x_f00))
n_f = nrow(x_f)

ytilde = matrix(NA, T, n_f)
for (t in 1:T){
  ytilde[t,] = rmnorm(1, x_f %*% beta[t,], sigma2[t]*diag(n_f))
}

## Distribution of posterior predictive samples
c.labels = c("A", "B", "C", "D")
par(mfrow=c(2,2))
for (j in 1:4){
  hist(ytilde[ , j], main = paste("Covariate Set", c.labels[j]),
       xlab = "log time", prob = T, breaks = 20)
}
par(mfrow=c(1,1))

## Posterior mean / 95% credible interval 
cbind(apply(ytilde, 2, mean),
      t(apply(ytilde, 2, quantile, c(0.025, 0.975))))
```

Tight Ends Bayesian Inference
```{r echo = TRUE}
# Data Formatting
te <- read.csv("TEs.csv")
te.full <- te[is.na(te$Forty) == FALSE, ]
te.full <- te.full[is.na(te.full$Bench) == FALSE, ]

prosp_te <- subset(prosp, Position == "TE")
prosp_te_full <- prosp_te[is.na(prosp_te$Forty) == FALSE, ]
prosp_te_full <- prosp_te_full[is.na(prosp_te_full$Bench) == FALSE, ]
future <- as.data.frame(cbind(prosp_te_full$Forty, prosp_te_full$Bench))
names(future) <- c("Forty", "Bench")

# Initial Regression
telm2 <- lm(AV16 ~ Forty + Bench, data = te.full)
summary(telm2)
te_bay <- as.data.frame(cbind(te.full$Pick.Number, te.full$Forty, te.full$Bench))
names(te_bay) <- c("Pick.Number", "Forty", "Bench")

# Bayesian Inference
fit = lm(Pick.Number ~ Forty + Bench, data = te_bay)
summary(fit)

y = te_bay$Pick.Number
n = length(y)
x = as.matrix(cbind(rep(1,n), te_bay[,2:3]))

  ## Compute quantities for speed
Vb = solve(t(x) %*% x) 
betahat = Vb %*% t(x) %*% y
s2 = t(y - x %*% betahat) %*% (y - x %*% betahat)

  ## MCMC settings
T = 10000
k = ncol(x)
sigma2 = rep(NA, T)
beta = matrix(NA, T, k)

  ## Sample from joint posterior
for (t in 1:T){
  
  ## Draw sigma2
  sigma2[t] = rigamma(1, (n-k)/2, s2/2)
  
  ## Draw beta
  beta[t,] = rmnorm(1, betahat, sigma2[t] * Vb)
  
}
par(mfrow=c(2,2))
hist(beta[,2], main = "Forty", xlab = expression(beta[1]))
hist(beta[,3], main = "Bench", xlab = expression(beta[2]))
hist(sigma2, main = "Variance", xlab = expression(sigma^2))
par(mfrow=c(1,1))

cat("Posterior mean of beta:", apply(beta, 2, mean))
cat("Quantiles for beta:") 
    apply(beta, 2, quantile, c(0.025, 0.5, 0.975))
cat("Quantiles for sigma^2:", quantile(sigma2, c(0.025, 0.5, 0.975)))

x_f00 = data.frame(Forty = future[,1],
                   Bench = future[,2])

# Predicting
predict(fit, x_f00, interval = "prediction")

# Predicting with Bayes
x_f = as.matrix(cbind(rep(1,12),x_f00))
n_f = nrow(x_f)

ytilde = matrix(NA, T, n_f)
for (t in 1:T){
  ytilde[t,] = rmnorm(1, x_f %*% beta[t,], sigma2[t]*diag(n_f))
}

## Distribution of posterior predictive samples
c.labels = c("A", "B", "C", "D")
par(mfrow=c(2,2))
for (j in 1:4){
  hist(ytilde[ , j], main = paste("Covariate Set", c.labels[j]),
       xlab = "log time", prob = T, breaks = 20)
}
par(mfrow=c(1,1))

## Posterior mean / 95% credible interval 
cbind(apply(ytilde, 2, mean),
      t(apply(ytilde, 2, quantile, c(0.025, 0.975))))
```
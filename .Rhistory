})
names(y.probs) = sapply(permuts, function(v) paste(v, collapse =' < '))
y.probs.stacked = stack(y.probs)[, c(2, 1)] # Reverse stack order
names(y.probs.stacked) = c('Inequality', 'Probability')
y.probs.stacked
(theta_prob=mean(all_mc_thetas[[1]]>all_mc_thetas[[2]]&all_mc_thetas[[1]]>all_mc_thetas[[3]]))
(y_prob=mean(mc_school[[1]]>mc_school[[2]]&mc_school[[1]]>mc_school[[3]]))
theta1.prob = mean(school.theta.mc[[1]] >
school.theta.mc[[2]] & school.theta.mc[[1]] >
school.theta.mc[[3]])
theta1.prob
y1.prob = mean(school.y.mc[[1]] > school.y.mc[[2]] & school.y.mc[[1]] > school.y.mc[[3]])
y1.prob
school.y.mc
mean(school.y.mc)
school.y.mc[1:10]
dim(school.y.mc)
theta=seq(0, 1, 0.1)
prob=dbinom(57, 100, theta)
bp=barplot(theta, round(prob,3), main='Barplot of Theta and Probability',ylab='Probability',xlab='Theta')
denominator=sum(prob)
bp=barplot(theta, round(prob/denominator,3), main='Bayesian Barplot of Theta and Probability',ylab='Probability',xlab='Theta')
continuous_theta=seq(0,1,0.0001)
prob=dbinom(57,100,continuous_theta)
plot(continuous_theta,prob,xlab='Theta',ylab='Posterior Density',main='Continuous Theta Probability')
y=dbeta(continuous_theta, 58, 44)
plot(continuous_theta,y,xlab='Theta',ylab='Posterior Density',main='Continuous Theta Probability')
na=16
nb=16
n=32
mu=75
vari0=100
mua=75.2
mub=77.5
sda=7.3
sdb=8.1
varia=sda**2
varib=sdb**2
vect=c(1,2,4,8,16,32)
probs=sapply(kap0nu0, function(fval) {
ka=fval+na
kb=fval+nb
va=fval+na
vb=fval+nb
mua_n=(fval*mu+na*mua)/ka
mub_n=(fval*mu+nb*mub)/kb
varia_n=(1/va)*(fval*vari0+(na-1)*varia+((fval*na)/ka)*(mua-mu0)**2)
varib_n=(1/vb)*(fval*vari0+(nb-1)*varib+((fval*nb)/kb)*(mub-mu0)**2)
mc_varia_n=1/rgamma(10000,va/2,varia_n*va/2)
mc_varib_n=1/rgamma(10000,vb/2,varib_n*vb/2)
mc_theta_a=rnorm(10000,mua_n,sqrt(mc_varia_n))
mc_theta_b=rnorm(10000,mub_n,sqrt(mc_varib_n))
mean(mc_theta_a<mc_theta_b)
})
na=16
nb=16
n=32
mu=75
vari0=100
mua=75.2
mub=77.5
sda=7.3
sdb=8.1
varia=sda**2
varib=sdb**2
vect=c(1,2,4,8,16,32)
probs=sapply(vect, function(fval) {
ka=fval+na
kb=fval+nb
va=fval+na
vb=fval+nb
mua_n=(fval*mu+na*mua)/ka
mub_n=(fval*mu+nb*mub)/kb
varia_n=(1/va)*(fval*vari0+(na-1)*varia+((fval*na)/ka)*(mua-mu0)**2)
varib_n=(1/vb)*(fval*vari0+(nb-1)*varib+((fval*nb)/kb)*(mub-mu0)**2)
mc_varia_n=1/rgamma(10000,va/2,varia_n*va/2)
mc_varib_n=1/rgamma(10000,vb/2,varib_n*vb/2)
mc_theta_a=rnorm(10000,mua_n,sqrt(mc_varia_n))
mc_theta_b=rnorm(10000,mub_n,sqrt(mc_varib_n))
mean(mc_theta_a<mc_theta_b)
})
qplot(vect, probs, geom = c('line', 'point'))
qplot(vect, probs, geom = c('line', 'point'),main='Science classroom Monte Carlo Analysis')
mean(mc_theta_a<mc_theta_b)
4.377-3.755
(4.377-3.755)/3.755
(4.377-3.755)/((3.755+4.377)/2)
plot(vect,probs)
plot(vect,probs,line)
qplot(vect, probs, geom = c('line', 'point'),main='Science classroom Monte Carlo Analysis')
1/0.1796
1/0.1777
(log(OR_youth_W)*wWy+log(OR_elders_W)*wWe)/(wWy+wWe)
wWy
wWe
one<- read.table(header=TRUE, text='
Age Disease Exposure Count
<40 D E 5
<40 nonD E 8
<40 D nonE 45
<40 nonD nonE 72
>=40 D E 25
>=40 nonD E 10
>=40 D nonE 25
>=40 nonD nonE 10
')
one
ct <- xtabs(Count ~ Exposure + Disease + Age, data=one)
ct
age_bin=rep(0,135)
for (i in 1:135){
if (data$agegp[i]>=3){
age_bin[i]=1
}
}
data_cols_added$age_bin=age_bin
youth=subset(data_cols_added,data_cols_added$age_bin==0)
elders=subset(data_cols_added,data_cols_added$age_bin==1)
youth_less_thans=subset(youth,youth$amount_bin==0)
youth_greater_thans=subset(youth,youth$amount_bin==1)
elders_less_thans=subset(elders,elders$amount_bin==0)
elders_greater_thans=subset(elders,elders$amount_bin==1)
(ay=sum(youth_less_thans$ncases))
(by=sum(youth_less_thans$ncontrols))
(cy=sum(youth_greater_thans$ncases))
(dy=sum(youth_greater_thans$ncontrols))
ny=ay+by+cy+dy
(ae=sum(elders_less_thans$ncases))
(be=sum(elders_less_thans$ncontrols))
(ce=sum(elders_greater_thans$ncases))
(de=sum(elders_greater_thans$ncontrols))
ne=ae+be+ce+de
(OR_youth=(ay*dy)/(by*cy))
(OR_elders=(ae*de)/(be*ce))
print('Mantel-Haenszel Method')
wMHy=by*cy/ny
wMHe=be*ce/ne
(OR_MH=(OR_youth*wMHy+OR_elders*wMHe)/(wMHy+wMHe))
#MH Confidence Interval
one<- read.table(header=TRUE, text='
Age Disease Exposure Count
<40 D E 5
<40 nonD E 8
<40 D nonE 45
<40 nonD nonE 72
>=40 D E 25
>=40 nonD E 10
>=40 D nonE 25
>=40 nonD nonE 10
')
ct <- xtabs(Count ~ Exposure + Disease + Age, data=one)
print('Woolf Method')
OR_youth_W=((ay+.5)*(dy+.5))/((by+.5)*(cy+.5))
OR_elders_W=((ae+.5)*(de+.5))/((be+.5)*(ce+.5))
wWy=((1/(ay+.5))+(1/(by+.5))+(1/(cy+.5))+(1/(dy+.5)))^(-1)
wWe=((1/(ae+.5))+(1/(be+.5))+(1/(ce+.5))+(1/(de+.5)))^(-1)
(OR_Woolf=exp((log(OR_youth_W)*wWy+log(OR_elders_W)*wWe)/(wWy+wWe)))
print('95% CI for youth')
(CI_low_youth=log(OR_youth)+qnorm(0.025)*sqrt(1/ay+1/by+1/cy+1/dy))
(CI_high_youth=log(OR_youth)+qnorm(0.975)*sqrt(1/ay+1/by+1/cy+1/dy))
print('95% CI for elders')
(CI_low_elders=log(OR_elders)+qnorm(0.025)*sqrt(1/ae+1/be+1/ce+1/de))
(CI_high_elders=log(OR_elders)+qnorm(0.975)*sqrt(1/ae+1/be+1/ce+1/de))
one<- read.table(header=TRUE, text='
Age Disease Exposure Count
<40 D E 26
<40 nonD E 408
<40 D nonE 30
<40 nonD nonE 64
>=40 D E 78
>=40 nonD E 258
>=40 D nonE 66
>=40 nonD nonE 45
')
ct <- xtabs(Count ~ Exposure + Disease + Age, data=one)
(ct <- xtabs(Count ~ Exposure + Disease + Age, data=one))
#MH Confidence Interval
one<- read.table(header=TRUE, text='
Age Disease Exposure Count
y D E 26
y nonD E 408
y D nonE 30
y nonD nonE 64
e D E 78
e nonD E 258
e D nonE 66
e nonD nonE 45
')
(ct <- xtabs(Count ~ Exposure + Disease + Age, data=one))
mantelhaen.test(ct)
log(OR_Woolf)+qnorm(0.025)*sqrt(1/(wWy+wWe))
log(OR_Woolf)+qnorm(0.975)*sqrt(1/(wWy+wWe))
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(stats)
library(fanplot)
armod=arima.sim(model=list(order=c(2,0,0),ar = c(1.4,-0.45)),n,sd=sqrt(1/4))
pacf(armod)
acf(armod)
acf(armod)
pacf(armod)
n=10000
a1=arima.sim(model=list(order=c(2,0,0),ar = c(1.2,-0.4)),n,sd=1)
n=1000
ar4=arima.sim(model=list(order=c(2,0,0),ar = c(1.4,-0.45)),n,sd=sqrt(1/4))
acf(ar4)
pacf(ar4)
n4=1000
ar4=arima.sim(model=list(order=c(2,0,0),ar = c(1.4,-0.45)),n4,sd=sqrt(1/4))
acf(ar4)
pacf(ar4)
n5=10000
a5=arima.sim(model=list(order=c(2,0,0),ar = c(1.2,-0.4)),n5,sd=1)
#Lags
reg1=lm(a5[2:n5]~a5[1:(n5-1)])
n5=10000
a5=arima.sim(model=list(order=c(2,0,0),ar = c(1.2,-0.4)),n5,sd=1)
#Lags
reg1=lm(a5[2:n5]~a5[1:(n5-1)])
reg2=lm(a5[3:n5]~a5[1:(n5-2)])
reg3=lm(a5[4:n5]~a5[1:(n5-3)])
reg4=lm(a5[5:n5]~a5[1:(n5-4)])
reg5=lm(a5[6:n5]~a5[1:(n5-5)])
reg1
reg2
reg3
reg4
reg5
partial=0
for(j in 2:6){
c=j
r=n5-j+1
lag=matrix(0,r,j)
for(i in 1:c){
lag[,i]=y[i:(i+r-1)]
}
lag=as.data.frame(lag)
fit=lm(lag$V1~.-1,data=lag)
partial[j]=coef(fit)[j-1]
}
(partial=partial[2:6])
plot(partial)
n4=1000
ar4=arima.sim(model=list(order=c(2,0,0),ar = c(-1.4,0.45)),n4,sd=sqrt(1/4))
n4=1000
ar4=arima.sim(model=list(order=c(2,0,0),ar = c(1.4,-0.45)),n4,sd=sqrt(1/4))
acf(ar4)
pacf(ar4)
ARMAacf(ar=c(1.2,-0.4),lag.max=5,pacf=TRUE)
(partial=partial[2:6])
ARMAacf(ar=c(1.2,-0.4),lag.max=5,pacf=TRUE)
x=seq(1,n5,1)
y=ts(a5)
length(y)
partial=0
for(j in 2:6){
c=j
r=n5-j+1
lag=matrix(0,r,j)
for(i in 1:c){
lag[,i]=y[i:(i+r-1)]
}
lag=as.data.frame(lag)
fit=lm(lag$V1~.-1,data=lag)
partial[j]=coef(fit)[j-1]
}
(partial=partial[2:6])
plot(partial)
ARMAacf(ar=c(1.2,-0.4),lag.max=5,pacf=TRUE)
coef
coef(fit)
lag
knitr::opts_chunk$set(echo = TRUE)
z = c(1,0,.9) # coefficients of the polynomial
(a = polyroot(z)) # print one root = 1 + i/sqrt(3)
z = c(1,0,.9) # coefficients of the polynomial
(a = polyroot(z)) # print one root = 1 + i/sqrt(3)
arg = Arg(a)/(2*pi)
(arg = Arg(a)/(2*pi))
1/arg
ar2 = arima.sim(list(order=c(2,0,0), ar=c(0,-.9)), n = 16)
z = c(1,0,.9) # coefficients of the polynomial
(a = polyroot(z)) # print one root = 1 + i/sqrt(3)
arg = Arg(a)/(2*pi)
1/arg
ar2 = arima.sim(list(order=c(2,0,0), ar=c(0,-.9)), n = 16)
plot(ar2, axes=FALSE, xlab="Time")
axis(2); axis(1, at=seq(0,16,by=4)); box()
abline(v=seq(0,16,by=4), lty=2)
ACF = ARMAacf(ar=c(0,-.9), ma=0, 50)
plot(ACF, type="h", xlab="lag")
abline(h=0)
acf(ar2)
n=100
ar1=arima.sim(list(order=c(1,1,0), ar=c(0.6)),n)
acf(ar1)
pacf(ar1)
ar2=arima.sim(list(order=c(1,0,0), ar=c(0.6)),n)
acf(ar2)
pacf(ar2)
ar3=arima.sim(list(order=c(0,1,0), ar=c(0.6)),n)
n=100
ar1=arima.sim(list(order=c(1,1,0), ar=c(0.6)),n)
acf(ar1)
pacf(ar1)
ar2=arima.sim(list(order=c(1,0,0), ar=c(0.6)),n)
acf(ar2)
pacf(ar2)
ar3=arima.sim(list(order=c(0,1,0), ar=c()),n)
acf(ar3)
pacf(ar3)
n=100
ar1=arima.sim(list(order=c(1,1,0), ar=c(0.6)),n)
acf(ar1)
pacf(ar1)
ar2=arima.sim(list(order=c(1,0,0), ar=c(0.6)),n)
acf(ar2)
pacf(ar2)
ar3=arima.sim(list(order=c(0,1,0), ar=c()),n)
acf(ar3)
pacf(ar3)
n=100
ar1=arima.sim(list(order=c(1,1,0), ar=c(0.6)),n)
acf(ar1)
pacf(ar1)
ar2=arima.sim(list(order=c(1,0,0), ar=c(0.6)),n)
acf(ar2)
pacf(ar2)
ar3=arima.sim(list(order=c(0,1,0), ar=c()),n)
acf(ar3)
pacf(ar3)
ar2=arima.sim(list(order=c(1,0,0), ar=c(0.6)),n)
acf(ar2)
pacf(ar2)
ar3=arima.sim(list(order=c(0,1,0), ar=c()),n)
acf(ar3)
pacf(ar3)
n=100
ar1=arima.sim(list(order=c(1,1,0), ar=c(0.6)),n)
acf(ar1)
pacf(ar1)
ar2=arima.sim(list(order=c(1,0,0), ar=c(0.6)),n)
acf(ar2)
pacf(ar2)
ar3=arima.sim(list(order=c(0,1,0), ar=c()),n)
acf(ar3)
pacf(ar3)
n=100
ar1=arima.sim(list(order=c(1,0,1), ar=c(0.6)),n)
n=100
ar1=arima.sim(list(order=c(1,1,0), ar=c(0.6)),n)
acf(ar1)
pacf(ar1)
ar2=arima.sim(list(order=c(1,0,0), ar=c(0.6)),n)
acf(ar2)
pacf(ar2)
ar3=arima.sim(list(order=c(0,1,0), ar=c()),n)
acf(ar3)
pacf(ar3)
??forecast
globtemp
library(astsa)
data('globtemp')
136/35
globtemp
sarima.for(globtemp,10,1,0,0)
linmod=lm(globtemp~time(globtemp),na.action=NULL)
resids=resid(linmod)
invisible(acf2(resids,max.lag=20))
sarima(resids,1,0,0,no.constant=T)
sarima(resids,1,0,0,no.constant=T)
sarima(resids,1,0,1,no.constant=T)
func1<-function(x){
for (i in 1:100){
if (i%3 == 0){
disp('hello')}
else{
disp('Facebook')}
}
}
source('~/.active-rstudio-document', echo=TRUE)
arma12f2 <- arima0(ARMA,order=c(1,0,1),include.mean=FALSE,method="ML")
library(astsa)
library(forecast)
arma12f2 <- arima0(ARMA,order=c(1,0,1),include.mean=FALSE,method="ML")
library(forecast)
ar20=arima.sim(list(order=c(0,1,0), ma=0.9, ar=0.9,500))
ar20=arima.sim(list(order=c(0,1,0), ma=0.9, ar=0.9,n=500))
ar20=arima.sim(list(order=c(0,1,0), ma=0.9, ar=c(0.9),n))
n=500
ar20=arima.sim(list(order=c(0,1,0), ma=0.9, ar=c(0.9),n))
ar20=arima.sim(list(order=c(1,0,1), ma=0.9, ar=c(0.9),n))
ar2 = arima.sim(list(order=c(2,0,0), ar=c(0,-.9)), n = 16)
ar2 = arima.sim(list(order=c(1,0,1), ar=c(0,-.9)), n = 16)
ar2 = arima.sim(list(order=c(1,0,1), ar=c(-.9)), n = 16)
ar2 = arima.sim(list(order=c(1,0,1), ma=0.9, ar=c(-.9)), n = 16)
ar2 = arima.sim(list(order=c(1,0,1), ma=0.9, ar=c(-.9)), n = 500)
ar2 = arima.sim(list(order=c(1,0,1), ma=0.9, ar=c(0.9)), n = 500)
ar20=arima.sim(list(order=c(1,0,1), ma=0.9, ar=c(0.9)), n = 500)
library(forecast)
ar20=arima.sim(list(order=c(1,0,1), ma=0.9, ar=c(0.9)), n = 500)
ar20.0 <- arima0(ar20,order=c(1,0,1),include.mean=FALSE,method="ML")
arma20.0$coef
arima.sim(list(order=c(1,0,1), ma=0.9, ar=c(0.9),n=500))
ar20=arima.sim(list(order=c(1,0,1), ma=0.9, ar=c(0.9)), 500)
ar20.0$coef
library(forecast)
ar20=arima.sim(list(order=c(1,0,1), ma=0.9, ar=c(0.9)), 500)
acf(ar20)
pacf(ar20)
ar20.0 <- arima0(ar20,order=c(1,0,1),include.mean=FALSE,method="ML")
ar20.0$coef
9500/97.5
64810000000/997
58.08/968*46
58.08-50.6
(58.08-50.6)/50.6
.7/4
350*1.44
350*1.2*1.2
430/4.5/1.6
2.3*1.07
2.3/.93
2.3/.9
7.3/3.2
60/7.2
289/1600
411/2158
582/2568
578/2375
592/2508
596/2709
215/671
160/511
35/160
55/160
1600*1.21
2568-1936
2568-1600*1.1*1.1
1.44/1.7
15*20.5
232.11-191.47
40.64*307500
.34*15/16
220000*36.13
8000000-7948600
220000*36.13-8000000
20*1.57
2.3+4.5+6.7
32+62+50
13.5/144
1.3/6.7
(19.4)^1/6
x=0.0323333
6.7*x*x*x*x*x*x
x=1.0323333
6.7*x*x*x*x*x*x
.8/32
1.5/50
0.005*1000000000
knitr::opts_chunk$set(echo = TRUE)
dat <- read.csv('DataUpdate1.csv')
have_played <- dat %>%
filter(Year != 2020)
library(dplyr)
dat <- read.csv('DataUpdate1.csv')
have_played <- dat %>%
filter(Year != 2020)
for (i in 1:nrow(have_played)){
if (is.na(have_played$ProBowls[i])){
have_played$ProBowls[i]=0
}
if (is.na(have_played$AllPros[i])){
have_played$AllPros[i]=0
}
}
have_played <- have_played %>%
mutate(Success = ProBowls + 2*AllPros) %>% # Can be arbitrary
arrange(desc(Success))
# Only uncomment below if necessary
# write.csv (have_played, 'havePlayed.csv')
head(have_played)
qbs <- filter (have_played, Position == 'QB')
head(qbs)
plot(qbs$Wonderlic)
plot(qbs$Wonderlic, qbs$Success)
qbs <- filter (have_played, Position == 'QB', Success > 1)
plot(qbs$Wonderlic, qbs$Success)
qbs <- filter (have_played, Position == 'QB', Success > 0)
plot(qbs$Wonderlic, qbs$Success)
setwd("~/15th Grade/STAT 411/NFLCombineAnalysis")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
dat <- read.csv('DataUpdate1.csv')
have_played <- dat %>%
filter(Year != 2020)
for (i in 1:nrow(have_played)){
if (is.na(have_played$ProBowls[i])){
have_played$ProBowls[i]=0
}
if (is.na(have_played$AllPros[i])){
have_played$AllPros[i]=0
}
}
have_played <- have_played %>%
mutate(Success = ProBowls + 2*AllPros) %>% # Can be arbitrary
arrange(desc(Success))
# Only uncomment below if necessary
# write.csv (have_played, 'havePlayed.csv')
qbs <- filter (have_played, Position == 'QB', Success > 0)
lm(Success ~ Wonderlic + Height + Weight, data = qbs)
# There being so many zeros makes this hella tough
